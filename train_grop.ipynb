{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bec36a",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18b776",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f951d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 2048\n",
    "lora_rank = 32\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen3-4B\",\n",
    "    max_seq_length = max_seq_length,   # Context length - can be longer, but uses more memory\n",
    "    fast_inference=True,  # Enable vLLM fast inference\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.85,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_rank,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Remove QKVO if out of memory\n",
    "    lora_alpha=lora_rank,\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Enable long context finetuning\n",
    "    random_state=3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b241ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750916d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "SYSTEM_PROMPT=\"\"\"You are a professional code assistant with expertise in code analysis and version control best practices.\n",
    "1. Your task is to analyze code changes (diffs), summarize their theme and core content.\n",
    "2. Generate a structured commit message inside <commit_message> and </commit_message> tags. Your message must strictly follow the rules provided by the user.\"\"\"\n",
    "\n",
    "USER_PROMPT=\"\"\"Task: generate a structured commit message based on the given code changes.\n",
    "\n",
    "Rules:\n",
    "- Commits MUST be prefixed with a type, which consists of a noun, `feat`, `fix`, etc., followed by an OPTIONAL scope, and a REQUIRED terminal colon and space.\n",
    "- The type `feat` MUST be used when a commit adds a new feature to your application or library.\n",
    "- The type `fix` MUST be used when a commit represents a bug fix for your application.\n",
    "- A scope MAY be provided after a type. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., `fix(parser)`:\n",
    "- A description MUST immediately follow the space after the type/scope prefix. The description is a short summary of the code changes, e.g., fix: array parsing issue when multiple spaces were contained in string.\n",
    "- A longer commit body MAY be provided after the short description, providing additional contextual information about the code changes. The body MUST begin one blank line after the description.\n",
    "- A footer of one or more lines MAY be provided one blank line after the body. The footer MUST contain meta-information about the commit, e.g., related pull-requests, reviewers, breaking changes, with one piece of meta-information per-line.\n",
    "- Breaking changes MUST be indicated at the very beginning of the body section, or at the beginning of a line in the footer section. A breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon and a space.\n",
    "- A description MUST be provided after the `BREAKING CHANGE`: , describing what has changed about the API, e.g., BREAKING CHANGE: environment variables now take precedence over config files.\n",
    "- Types other than `feat` and `fix` MAY be used in your commit messages.\n",
    "- The units of information that make up conventional commits MUST NOT be treated as case sensitive by implementors, with the exception of BREAKING CHANGE which MUST be uppercase.\n",
    "- A `!` MAY be appended prior to the `:` in the type/scope prefix, to further draw attention to breaking changes. `BREAKING CHANGE: description` MUST also be included in the body or footer, along with the `!` in the prefix.\n",
    "\n",
    "Examples:\n",
    "## Commit message with description and breaking change in body\n",
    "```\n",
    "feat: allow provided config object to extend other configs\n",
    "\n",
    "BREAKING CHANGE: `extends` key in config file is now used for extending other config files\n",
    "```\n",
    "## Commit message with optional `!` to draw attention to breaking change\n",
    "```\n",
    "chore!: drop Node 6 from testing matrix\n",
    "\n",
    "BREAKING CHANGE: dropping Node 6 which hits end of life in April\n",
    "```\n",
    "## Commit message with no body\n",
    "```\n",
    "docs: correct spelling of CHANGELOG\n",
    "```\n",
    "## Commit message with scope\n",
    "```\n",
    "feat(lang): add polish language\n",
    "```\n",
    "## Commit message for a fix using an (optional) issue number.\n",
    "```\n",
    "fix: correct minor typos in code\n",
    "\n",
    "see the issue for details on the typos fixed\n",
    "\n",
    "closes issue #12\n",
    "```\n",
    "\n",
    "You must use this format:\n",
    "\n",
    "<commit_message>\n",
    "...\n",
    "<\\commit_message>\n",
    "\"\"\"\n",
    "\n",
    "# ds = datasets.load_dataset(\"circle33/conventional_commits\")\n",
    "ds = datasets.load_from_disk(\"/home/circle/code/AImmit_ai/dataset_generation\")\n",
    "\n",
    "ds = ds.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360e035",
   "metadata": {},
   "source": [
    "# Reward functions\n",
    "\n",
    "1. Format reward: ensure the output is in the correct format. (10 points)\n",
    "2. Check the output for similarity to known commit messages. The higher the similarity, the higher the reward. (90 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "pattern = r\"<commit_message>.*</commit_message>\"\n",
    "regex = re.compile(pattern, re.DOTALL)\n",
    "\n",
    "def format_reward(prompts, completions, **kwargs):\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    return [\n",
    "        0.0 if not regex.match(response) else 10.0 for response in responses\n",
    "    ]\n",
    "\n",
    "CONVENTIONAL_COMMIT_REGEX = re.compile(\n",
    "    r\"^(?P<type>[a-zA-Z_]+)\"  # type (e.g., feat, fix, chore)\n",
    "    r\"(?:\\((?P<scope>[^\\)\\n]+)\\))?\"  # Optional scope\n",
    "    r\"(?P<breaking_indicator>!)?\"  # Optional breaking change indicator\n",
    "    r\":\\s*(?P<description>[^\\n]+)\"  # Description\n",
    "    r\"(?:(?:\\r\\n|\\r|\\n){2}(?P<body>.*))?\", # Optional body\n",
    "    re.DOTALL | re.MULTILINE\n",
    ")\n",
    "\n",
    "def parse_commit(commit_message: str):\n",
    "    \"\"\"\n",
    "    Parses a commit message string into its Conventional Commit components.\n",
    "    \"\"\"\n",
    "    match = CONVENTIONAL_COMMIT_REGEX.match(commit_message.strip())\n",
    "    if not match:\n",
    "        return {\n",
    "            \"type\": None,\n",
    "            \"scope\": None,\n",
    "            \"is_breaking_change_header\": False,\n",
    "            \"description\": commit_message.strip(), # Fallback to full message as description\n",
    "            \"body\": None,\n",
    "            \"breaking_change_footer\": None,\n",
    "            \"is_breaking_change\": False,\n",
    "            \"raw\": commit_message,\n",
    "            \"parse_success\": False\n",
    "        }\n",
    "\n",
    "    components = match.groupdict()\n",
    "    parsed_type = components.get(\"type\")\n",
    "    parsed_scope = components.get(\"scope\") # Might be None\n",
    "    breaking_indicator = components.get(\"breaking_indicator\") == \"!\"\n",
    "    parsed_description = components.get(\"description\", \"\").strip()\n",
    "\n",
    "    full_body_and_footers = components.get(\"body\")\n",
    "    parsed_body = None\n",
    "    parsed_breaking_change_footer_desc = None\n",
    "\n",
    "    if full_body_and_footers:\n",
    "        # Simple split for body and footers (might need refinement for multiple footers)\n",
    "        parts = full_body_and_footers.split('\\n\\n', 1)\n",
    "        parsed_body = parts[0].strip()\n",
    "        if len(parts) > 1: # check if breaking change was not caught by regex directly\n",
    "            footers_part = parts[1]\n",
    "            bc_match = re.search(r\"BREAKING CHANGE:\\s*([^\\n]+)\", footers_part, re.IGNORECASE)\n",
    "            if bc_match:\n",
    "                parsed_breaking_change_footer_desc = bc_match.group(1).strip()\n",
    "        elif parsed_body and \"BREAKING CHANGE:\" in parsed_body:\n",
    "            # Handle case where BREAKING CHANGE might be in the first part of body\n",
    "            bc_match_in_body = re.search(r\"BREAKING CHANGE:\\s*([^\\n]+)\", parsed_body, re.IGNORECASE)\n",
    "            if bc_match_in_body:\n",
    "                parsed_breaking_change_footer_desc = bc_match_in_body.group(1).strip()\n",
    "                # Potentially remove this from body if it's distinctly a footer\n",
    "                parsed_body = parsed_body.split(\"BREAKING CHANGE:\")[0].strip()\n",
    "\n",
    "    is_breaking = breaking_indicator or (parsed_breaking_change_footer_desc is not None)\n",
    "\n",
    "    return {\n",
    "        \"type\": parsed_type,\n",
    "        \"scope\": parsed_scope,\n",
    "        \"is_breaking_change_header\": breaking_indicator,\n",
    "        \"description\": parsed_description,\n",
    "        \"body\": full_body_and_footers, # Ensure empty string if None\n",
    "        \"breaking_change_footer\": parsed_breaking_change_footer_desc,\n",
    "        \"is_breaking_change\": is_breaking,\n",
    "        \"raw\": commit_message,\n",
    "        \"parse_success\": True\n",
    "    }\n",
    "\n",
    "CROSS_MODEL = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "ROUGE_SCORER = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def cross_compare(model_commit, input_commit, scale=1.0):\n",
    "    \"\"\"\n",
    "    Compares two commit messages using a cross-encoder model and returns a similarity score.\n",
    "    The score is normalized to a 0-scale.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        score = CROSS_MODEL.predict([model_commit, input_commit])\n",
    "        return score * scale\n",
    "    except Exception as e:\n",
    "        print(f\"Error during semantic similarity calculation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def rouge_compare(model_commit, input_commit, scale=1.0):\n",
    "    \"\"\"\n",
    "    Compares two commit messages using ROUGE-L and returns a similarity score.\n",
    "    The score is normalized to a 0-scale.\n",
    "    \"\"\"\n",
    "    if not model_commit and not input_commit:\n",
    "        return scale # Both are empty, return scale as score\n",
    "    try:\n",
    "        scores = ROUGE_SCORER.score(model_commit, input_commit)\n",
    "        return scores['rougeL'].fmeasure * scale\n",
    "    except Exception as e:\n",
    "        print(f\"Error during ROUGE calculation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def score_reward(prompts, completions, commit_message, diff, **kwargs):\n",
    "    \"\"\"\n",
    "    Parse success score: 5.0 if all completions parse successfully, else 0.0\n",
    "    Breaking change score: 5.0 if breaking change is same as the given Breaking change commit, else 0.0\n",
    "    Commit type score: 5.0 if type is same as the given type else 0.0\n",
    "    Commit scope score: 5.0 if scope is same as the given scope else 0.0\n",
    "    Commit description score: 35.0 as the highest score for similarity to the given description\n",
    "    Commit body score: 35.0 as the highest score for rougeL to the given body\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    for content, input_commit, input_diff in zip(responses, commit_message, diff):\n",
    "        # Parse the commit message\n",
    "        model_commit = parse_commit(content)\n",
    "        raw_commit = parse_commit(input_commit)\n",
    "\n",
    "        # Check if parsing was successful\n",
    "        if not model_commit[\"parse_success\"]:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        scope_match = (model_commit[\"scope\"] == raw_commit[\"scope\"]) if raw_commit[\"scope\"] else True\n",
    "\n",
    "        # Calculate scores\n",
    "        parse_success_score = 5.0 if model_commit[\"parse_success\"] else 0.0\n",
    "        breaking_change_score = 5.0 if (model_commit[\"is_breaking_change\"] == raw_commit[\"is_breaking_change\"]) else 0.0\n",
    "        type_score = 5.0 if model_commit[\"type\"] == raw_commit[\"type\"] else 0.0\n",
    "        scope_score = 5.0 if scope_match else 0.0\n",
    "\n",
    "        # Body score based on Rouge similarity (not implemented here, placeholder)\n",
    "        description_score = cross_compare(model_commit=model_commit[\"description\"], input_commit=raw_commit[\"description\"], scale=35.0)\n",
    "        body_score = rouge_compare(model_commit=model_commit[\"body\"] or \"\", input_commit=raw_commit[\"body\"] or \"\", scale=35.0)\n",
    "\n",
    "        scores.append(\n",
    "            parse_success_score +\n",
    "            breaking_change_score +\n",
    "            type_score +\n",
    "            scope_score +\n",
    "            description_score +\n",
    "            body_score\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49776164",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "tokenized_prompts = [\n",
    "    tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True)\n",
    "    for prompt in ds['prompt']\n",
    "]\n",
    "exact_max_prompt_length = max(\n",
    "    [len(tokenized_prompt) for tokenized_prompt in tokenized_prompts]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_prompt_length = 448  # manually adjusted\n",
    "new_model_id=\"circle33/qwen-commit-7b-grpo\"\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 8e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.01,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_generations = 8, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    max_grad_norm = 0.1,\n",
    "    output_dir = \"outputs\",\n",
    "    overwrite_output_dir = True,\n",
    "    push_to_hub = True,\n",
    "    hub_model_id=new_model_id,\n",
    "    hub_strategy=\"every_save\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"GRPO-reboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs=[\n",
    "        format_reward,\n",
    "        score_reward,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = ds,\n",
    ")\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AImmit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
